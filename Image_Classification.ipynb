{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2e57f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.8 tensorflow-gpu==2.8 opencv-python matplotlib  protobuf==3.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c3fdce-9392-4a66-8d79-247b91f56c11",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86433b8-b814-409d-9dfa-c2b9613230c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59c5f4-5128-4fb8-b6cb-8e6eba448e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5fa039-fa46-4bb8-b0ff-b7abf1f64924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b221d-9a82-43d8-a0ac-9771f7523796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c886c0-aa88-456d-8c54-0c0f4b0761ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521925cb-e33b-4add-bd73-5ee59e63f009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0770a3c2-1618-452f-8ed5-a2d4047e1aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d9fa2-0dbc-4ad3-8c84-fbc62c46816d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb235a-a054-497f-aa38-22b33a417ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5265cf-4241-4387-b0ec-5d1ffd79dee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d391d-3f79-404a-a86a-6030459edffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc2271-c309-4bbf-b607-a22dbe35e1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 marvel, 0 dc\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e886c5f-9432-4b11-805c-cf9f2aa9308a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53cfd2-e523-4ee0-a4a9-5c596a769a63",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f355bc0-5c41-4421-8d9f-0a6809782e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d86da4-5d2c-4054-8a8b-83294806ab9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db2a78-7503-485d-a6f8-b61eb1888576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size+val_size+test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b3755-633b-494a-9cc9-e15fd0a7b5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceab320-f23f-49ad-ac86-d89acb7e744e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615f32d-a6d7-4022-ad84-bb4813f794dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88140b62-0f2c-4bea-af47-d672e107a700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter layers for model\n",
    "\n",
    "# 2d convolution layer used for feature extraction from images\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3))) #relu function converts negative values to 0\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# dense takes output from all previous layers\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) #sigmoid keeps values between 0 and 1 which is needed for image classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de10da-03f2-42f9-a8fa-5f9ff0a67b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9366bd-4a36-4e34-b13c-eb8f2380ee89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2ff76-5491-4587-bb6b-dd72d13c7f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6861e-f6d0-4a66-b16d-cd9bfa801f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031da524-cc31-486d-b42f-43875aa6cef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f3381-66d2-4e93-be01-ba16315c62a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b6d69-1e54-4a4e-aa75-fbdad322c053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a521bf0-e5d3-4380-ab2e-42b790a67d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71877490-dea7-42f8-870f-81a76842b270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e0afb-a601-4ea5-97fc-1fa310e5de65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dffdf24-31cc-44b9-9ee5-970b87bd1403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe6f8d-de2f-4bae-a43f-0a21d09c7f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('hulk.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa240541-b776-4796-b254-08ec67ece812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919aadd9-ef7a-4f72-bd62-6b3e83aa8914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e8c3f-4941-43a2-bba7-8826ff130e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84957c-bc91-4cc4-b9a1-30e595d09a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Marvel')\n",
    "else:\n",
    "    print(f'Predicted class is DC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835436bb-1942-4cf9-b66b-c449f68208f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc930a67-45c2-467a-a58e-503410ac56b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','imageclassifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a73862-a2b3-42ea-b152-64d8f0606077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models','imageclassifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0773f622-42d9-4ec2-b66b-03c97c50096f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b34c5f2-eebc-4940-ac46-d6bf24205a38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageclassification",
   "language": "python",
   "name": "imageclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
